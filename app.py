import os
from flask import Flask, request, jsonify
import requests
import random
from datetime import datetime, timedelta
import logging
import certifi

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# ===== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =====
GEMINI_KEYS = [
    key.strip().strip('"').strip("'")
    for key in os.getenv('GEMINI_KEYS', '').split(',')
    if key.strip()
]
YOUR_MASTER_KEY = os.getenv('MASTER_KEY', '')
GEMINI_MODEL = os.getenv('GEMINI_MODEL', 'gemini-2.5-pro')
MAX_INPUT_TOKENS = int(os.getenv('MAX_INPUT_TOKENS', 2048000))
MAX_OUTPUT_TOKENS = int(os.getenv('MAX_OUTPUT_TOKENS', 65536))
DEFAULT_OUTPUT_TOKENS = int(os.getenv('DEFAULT_OUTPUT_TOKENS', 60000))

# –ù–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ OpenRouter (–±–µ–∑ —Å–º–µ–Ω—ã API)
MIMIC_OPENROUTER = os.getenv('MIMIC_OPENROUTER', 'false').lower() == 'true'

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–π
if not GEMINI_KEYS:
    raise ValueError("‚ùå No Gemini keys found in environment variables")

if not YOUR_MASTER_KEY:
    raise ValueError("‚ùå No master key found in environment variables")

key_usage = {key: {'requests': 0, 'last_used': None, 'errors': 0} for key in GEMINI_KEYS}

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
DETAILED_INSTRUCTION = """You are Gemini 2.5 Pro, a large language model from google.

Formatting Rules:
- Use Markdown **only when semantically appropriate**. Examples: `inline code`, ```code fences```, tables, and lists.
- In assistant responses, format file names, directory paths, function names, and class names with backticks (`).
- For math: use \( and \) for inline expressions, and \[ and \] for display (block) math."""
class KeyBalancer:
    """
    –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫ –∫–ª—é—á–µ–π —Å —É—á–µ—Ç–æ–º –æ—à–∏–±–æ–∫ –∏ cooldown.
    """
    def __init__(self):
        self.cooldown_period = timedelta(minutes=5)

    def get_best_key(self):
        now = datetime.now()
        available_keys = [
            k for k, v in key_usage.items()
            if v['errors'] < 3 and (v['last_used'] is None or now - datetime.fromisoformat(v['last_used']) > self.cooldown_period)
        ]
        if not available_keys:
            available_keys = GEMINI_KEYS  # Fallback –Ω–∞ –≤—Å–µ –∫–ª—é—á–∏
        key = min(available_keys, key=lambda k: key_usage[k]['requests'])
        return key

balancer = KeyBalancer()

# ===== ENDPOINT –î–õ–Ø SILLYTAVERN =====
@app.route('/v1/models', methods=['GET'])
def list_models():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    return jsonify({
        "object": "list",
        "data": [
            {
                "id": GEMINI_MODEL,
                "object": "model",
                "created": 1686935000,
                "owned_by": "google",
                "limits": {
                    "max_input_tokens": MAX_INPUT_TOKENS,
                    "max_output_tokens": MAX_OUTPUT_TOKENS
                }
            }
        ]
    })

# ===== ENDPOINTS –î–õ–Ø JANITORAI =====
@app.route('/v1/engines', methods=['GET'])
def list_engines():
    """–ê–Ω–∞–ª–æ–≥ list_models –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏."""
    return list_models()

@app.route('/v1/completions', methods=['POST'])
def completions():
    """–ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ chat_completions –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å JanitorAI."""
    logger.info("JanitorAI using chat format, redirecting to chat_completions")
    return chat_completions()

# ===== OPENAI-–°–û–í–ú–ï–°–¢–ò–ú–´–ô API =====
@app.route('/v1/chat/completions', methods=['POST', 'OPTIONS'])
def chat_completions():
    """OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–∞—Ç–∞ —á–µ—Ä–µ–∑ Gemini."""
    if request.method == 'OPTIONS':
        return '', 200

    try:
        data = request.json
        if not data or 'messages' not in data:
            return jsonify({"error": "Invalid request format"}), 400

        gemini_key = balancer.get_best_key()
        key_usage[gemini_key]['requests'] += 1
        key_usage[gemini_key]['last_used'] = datetime.now().isoformat()

        logger.info(f"Using key: {gemini_key[:20]}... | Requests: {key_usage[gemini_key]['requests']}")

        contents = []
        system_instruction = DETAILED_INSTRUCTION

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        if MIMIC_OPENROUTER:
            # –ò–º–∏—Ç–∞—Ü–∏—è OpenRouter: –í–∫–ª—é—á–∞–µ–º system –∫–∞–∫ –ø–µ—Ä–≤–æ–µ 'user' —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ contents (–¥–ª—è –ø–æ—Ö–æ–∂–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–º–ø—Ç–∞)
            contents.append({
                "role": "user",
                "parts": [{"text": f"System instruction: {system_instruction}"}]
            })
            system_instruction = ""  # –û—Ç–∫–ª—é—á–∞–µ–º separate, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            logger.info("Mimicking OpenRouter prompt format: System as first user message")

        for msg in data["messages"]:
            role = "user" if msg["role"] == "user" else "model"
            contents.append({
                "role": role,
                "parts": [{"text": msg["content"]}]
            })

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º max_tokens —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–æ–≤ Gemini
        requested_tokens = data.get("max_tokens", DEFAULT_OUTPUT_TOKENS)
        max_output_tokens = min(requested_tokens, MAX_OUTPUT_TOKENS)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ OpenRouter (–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å, –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å)
        temperature = data.get("temperature", 0.95)  # Default –∫–∞–∫ –≤ Gemini/OpenRouter –¥–ª—è creativity
        top_p = data.get("top_p", 0.95)
        

        gemini_data = {
            "contents": contents,
        }
        if system_instruction:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ MIMIC
            gemini_data["system_instruction"] = {
                "parts": [{"text": system_instruction}]
            }
        gemini_data["generationConfig"] = {
            "maxOutputTokens": max_output_tokens,
            "temperature": temperature,  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
            "topP": top_p,              # –î–æ–±–∞–≤–ª–µ–Ω–æ
         
            # JanitorAI —Å–∞–º –ø–µ—Ä–µ–¥–∞–µ—Ç temperature, top_p, etc —á–µ—Ä–µ–∑ data.get()
        }
        # –ü–û–õ–ù–û–ï –û–¢–ö–õ–Æ–ß–ï–ù–ò–ï –¶–ï–ù–ó–£–†–´
        gemini_data["safetySettings"] = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_NONE"
            }
        ]

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∫ Gemini —Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π SSL
        response = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={gemini_key}",
            json=gemini_data,
            headers={'Content-Type': 'application/json'},
            timeout=120,
            verify=certifi.where()
        )

        if response.status_code == 429:
            key_usage[gemini_key]['errors'] += 1
            key_usage[gemini_key]['last_used'] = datetime.now().isoformat()  # –î–ª—è cooldown
            logger.warning(f"Rate limit for key: {gemini_key[:20]}... Switching key.")
            return chat_completions()  # –†–µ–∫—É—Ä—Å–∏—è, –Ω–æ —Å cooldown –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ç–ª–∏

        if response.status_code != 200:
            key_usage[gemini_key]['errors'] += 1
            logger.error(f"Gemini API error {response.status_code} for key: {gemini_key[:20]}...")
            return jsonify({"error": f"Gemini API error: {response.status_code}"}), 500

        gemini_response = response.json()

        if ('candidates' not in gemini_response or
            not gemini_response['candidates'] or
            'content' not in gemini_response['candidates'][0] or
            'parts' not in gemini_response['candidates'][0]['content']):
            logger.error(f"Invalid Gemini response structure: {gemini_response}")
            return jsonify({"error": "Invalid response from Gemini API"}), 500

        response_text = gemini_response["candidates"][0]["content"]["parts"][0]["text"]

        total_input_chars = sum(len(msg["content"]) for msg in data["messages"])

        openai_format = {
            "id": f"chatcmpl-{random.randint(1000,9999)}",
            "object": "chat.completion",
            "created": int(datetime.now().timestamp()),
            "model": GEMINI_MODEL,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": response_text
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": total_input_chars // 4,
                "completion_tokens": len(response_text) // 4,
                "total_tokens": (total_input_chars + len(response_text)) // 4
            }
        }

        logger.info(f"‚úÖ Success! Input: {total_input_chars} chars, Output: {len(response_text)} chars")
        return jsonify(openai_format)

    except requests.Timeout:
        logger.error(f"Timeout for key: {gemini_key}")
        key_usage[gemini_key]['errors'] += 1
        return chat_completions()
    except Exception as e:
        logger.exception(f"‚ùå Unexpected error: {e}")
        return jsonify({"error": str(e)}), 500

# ===== –ê–£–¢–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–Ø =====
@app.before_request
def authenticate():
    if request.method == 'OPTIONS':
        return None

    if request.endpoint in ['chat_completions', 'list_models', 'completions']:
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({"error": "Authorization header required"}), 401
        api_key = auth_header.replace('Bearer ', '')
        if api_key != YOUR_MASTER_KEY:
            return jsonify({"error": "Invalid API key"}), 401

# ===== CORS =====
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')  # –î–ª—è production –æ–≥—Ä–∞–Ω–∏—á—å—Ç–µ origins
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
    return response

# ===== –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò =====
@app.route('/v1/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏."""
    return jsonify({
        "model": GEMINI_MODEL,
        "max_input_tokens": MAX_INPUT_TOKENS,
        "max_output_tokens": MAX_OUTPUT_TOKENS,
        "features": ["large_context", "multimodal", "reasoning"]
    })

# ===== HEALTH CHECK =====
@app.route('/health', methods=['GET'])
def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–∏—Å–∞."""
    return jsonify({
        "status": "ok",
        "service": "Gemini Proxy", 
        "timestamp": datetime.now().isoformat(),
        "keys_available": len(GEMINI_KEYS)
        
    })

# ===== –ì–õ–ê–í–ù–ê–Ø –°–¢–†–ê–ù–ò–¶–ê =====
@app.route('/')
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
    return """
    <html>
        <head>
            <title>üöÄ Gemini Proxy API</title>
            <style>
                body { font-family: Arial, sans-serif; max-width: 800px; margin: 40px auto; padding: 20px; }
                h1 { color: #333; }
                ul { line-height: 1.6; }
                a { color: #007bff; text-decoration: none; }
                a:hover { text-decoration: underline; }
            </style>
        </head>
        <body>
            <h1>üöÄ Gemini Proxy API</h1>
            <p>Server is running successfully! ‚úÖ</p>
            <p>Available endpoints:</p>
            <ul>
                <li><a href="/health">/health</a> - Status check</li>
                <li><a href="/v1/models">/v1/models</a> - List models</li>
                <li>POST /v1/chat/completions - Main chat API</li>
                <li>POST /v1/completions - JanitorAI compatibility</li>
            </ul>
            <p><strong>Usage:</strong> Set API URL to <code>https://meow-meow-mme0.onrender.com/v1</code> in SillyTavern/JanitorAI</p>
        </body>
    </html>
    """

if __name__ == '__main__':
    print("üöÄ Production Gemini Proxy starting...")
    print(f"üìä Available keys: {len(GEMINI_KEYS)}")
    print(f"üîë Your master key: {YOUR_MASTER_KEY[:10]}...")
    print(f"ü§ñ Model: {GEMINI_MODEL}")
    print(f"üìñ Context: {MAX_INPUT_TOKENS:,} tokens")
    print(f"üìù Output: {MAX_OUTPUT_TOKENS:,} tokens")
    print("üìç Endpoint: https://meow-meow-mme0.onrender.com/v1")

    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
